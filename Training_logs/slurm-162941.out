[INFO] SLURM_JOB_TMP is: /local/slurmjobs/162941
[INFO] Using GPU: 0
[INFO] Staging archive to node SSD...
'/homes/nnebeling/thesis/precomputed_7G_2Chunk.zip' -> '/local/slurmjobs/162941/precomputed_7G_2Chunk.zip'
[INFO] Unpacking on SSD...
[OK] Unpacked. Top-level contents:
.
precomputed_7G_2Chunk
precomputed_7G_2Chunk/Chill House
precomputed_7G_2Chunk/Zyzz Music
precomputed_7G_2Chunk/Emotional Techno
precomputed_7G_2Chunk/Party House
precomputed_7G_2Chunk/Chiller vibe goa
precomputed_7G_2Chunk/Dark Techno
precomputed_7G_2Chunk/Party Goa
[INFO] Starting training...
2025-09-19 06:56:38,221 - __main__ - INFO - Loading configuration...
2025-09-19 06:56:38,223 - __main__ - INFO - set_float32_matmul_precision=high
2025-09-19 06:56:38,223 - __main__ - INFO - TF32: matmul=True, cudnn=True
2025-09-19 06:56:38,604 - __main__ - INFO - Experiment: Testing 2 chunks per track
2025-09-19 06:56:38,605 - __main__ - INFO - Description: Dataset size 1x5
2025-09-19 06:56:38,606 - __main__ - INFO - Random seeds set to 23
2025-09-19 06:56:38,606 - __main__ - INFO - Loading data splits...
2025-09-19 06:56:38,606 - __main__ - INFO - Generating train/test splits from preprocessed features
2025-09-19 06:56:38,606 - __main__ - INFO - Generating track-level splits to prevent data leakage...
2025-09-19 06:56:38,607 - __main__ - INFO - Subgenre Chill House: 81 tracks, 162 chunks total
2025-09-19 06:56:38,608 - __main__ - INFO - Subgenre Chiller vibe goa: 54 tracks, 108 chunks total
2025-09-19 06:56:38,609 - __main__ - INFO - Subgenre Dark Techno: 86 tracks, 172 chunks total
2025-09-19 06:56:38,610 - __main__ - INFO - Subgenre Emotional Techno: 75 tracks, 150 chunks total
2025-09-19 06:56:38,611 - __main__ - INFO - Subgenre Party Goa: 62 tracks, 124 chunks total
2025-09-19 06:56:38,612 - __main__ - INFO - Subgenre Party House: 69 tracks, 138 chunks total
2025-09-19 06:56:38,613 - __main__ - INFO - Subgenre Zyzz Music: 77 tracks, 154 chunks total
2025-09-19 06:56:38,613 - __main__ - INFO - Subgenre Chill House: 65 train tracks, 16 test tracks
2025-09-19 06:56:38,613 - __main__ - INFO - Subgenre Chiller vibe goa: 44 train tracks, 10 test tracks
2025-09-19 06:56:38,613 - __main__ - INFO - Subgenre Dark Techno: 69 train tracks, 17 test tracks
2025-09-19 06:56:38,613 - __main__ - INFO - Subgenre Emotional Techno: 60 train tracks, 15 test tracks
2025-09-19 06:56:38,613 - __main__ - INFO - Subgenre Party Goa: 50 train tracks, 12 test tracks
2025-09-19 06:56:38,613 - __main__ - INFO - Subgenre Party House: 56 train tracks, 13 test tracks
2025-09-19 06:56:38,613 - __main__ - INFO - Subgenre Zyzz Music: 62 train tracks, 15 test tracks
2025-09-19 06:56:38,614 - __main__ - INFO - Generating training triplets from train tracks...
2025-09-19 06:56:38,614 - __main__ - INFO - Train triplet generation config:
2025-09-19 06:56:38,614 - __main__ - INFO -   Max positive tracks per anchor: 5
2025-09-19 06:56:38,614 - __main__ - INFO -   Triplets per positive track: 1
2025-09-19 06:56:38,614 - __main__ - INFO -   Expected triplets per anchor: ~5
2025-09-19 06:56:38,615 - __main__ - INFO - Train - Subgenre Chill House: 650 triplets from 65 tracks
2025-09-19 06:56:38,616 - __main__ - INFO - Train - Subgenre Chiller vibe goa: 440 triplets from 44 tracks
2025-09-19 06:56:38,618 - __main__ - INFO - Train - Subgenre Dark Techno: 690 triplets from 69 tracks
2025-09-19 06:56:38,620 - __main__ - INFO - Train - Subgenre Emotional Techno: 600 triplets from 60 tracks
2025-09-19 06:56:38,621 - __main__ - INFO - Train - Subgenre Party Goa: 500 triplets from 50 tracks
2025-09-19 06:56:38,622 - __main__ - INFO - Train - Subgenre Party House: 560 triplets from 56 tracks
2025-09-19 06:56:38,624 - __main__ - INFO - Train - Subgenre Zyzz Music: 620 triplets from 62 tracks
2025-09-19 06:56:38,624 - __main__ - INFO - Generating test triplets from test tracks...
2025-09-19 06:56:38,624 - __main__ - INFO - Test triplet generation config:
2025-09-19 06:56:38,624 - __main__ - INFO -   Max positive tracks per anchor: 5
2025-09-19 06:56:38,624 - __main__ - INFO -   Triplets per positive track: 1
2025-09-19 06:56:38,624 - __main__ - INFO -   Expected triplets per anchor: ~5
2025-09-19 06:56:38,624 - __main__ - INFO - Test - Subgenre Chill House: 160 triplets from 16 tracks
2025-09-19 06:56:38,625 - __main__ - INFO - Test - Subgenre Chiller vibe goa: 100 triplets from 10 tracks
2025-09-19 06:56:38,625 - __main__ - INFO - Test - Subgenre Dark Techno: 170 triplets from 17 tracks
2025-09-19 06:56:38,625 - __main__ - INFO - Test - Subgenre Emotional Techno: 150 triplets from 15 tracks
2025-09-19 06:56:38,626 - __main__ - INFO - Test - Subgenre Party Goa: 120 triplets from 12 tracks
2025-09-19 06:56:38,626 - __main__ - INFO - Test - Subgenre Party House: 130 triplets from 13 tracks
2025-09-19 06:56:38,626 - __main__ - INFO - Test - Subgenre Zyzz Music: 150 triplets from 15 tracks
2025-09-19 06:56:38,627 - __main__ - INFO - ✓ NO DATA LEAKAGE: 406 unique train tracks, 98 unique test tracks
2025-09-19 06:56:38,627 - __main__ - INFO - Total: 4060 train triplets, 980 test triplets
2025-09-19 06:56:38,627 - __main__ - INFO - Creating datasets...
2025-09-19 06:56:38,674 - __main__ - INFO - Initialized dataset (train) with 4060 triplets (resample_train_samples=False)
2025-09-19 06:56:38,685 - __main__ - INFO - Initialized dataset (test) with 980 triplets (resample_train_samples=False)
2025-09-19 06:56:38,685 - __main__ - INFO - Initializing model...
2025-09-19 06:56:38,685 - __main__ - INFO - Using device: cuda
2025-09-19 06:56:38,685 - __main__ - INFO - Loading pretrained model: MIT/ast-finetuned-audioset-10-10-0.4593
2025-09-19 06:56:40,680 - __main__ - INFO - MLP Projection Head Architecture: 768 -> 512 -> 128
2025-09-19 06:56:40,680 - __main__ - INFO -   Activation: relu, Dropout: 0.15
2025-09-19 06:56:40,680 - __main__ - INFO -   Total parameters: 459,392
2025-09-19 06:56:40,680 - __main__ - INFO - Model initialized with projection to 128D
2025-09-19 06:56:40,680 - __main__ - INFO - Margin scheduling: 0.5 → 0.5 over 1 epochs
2025-09-19 06:56:40,680 - __main__ - INFO - Negative mining: none
2025-09-19 06:56:40,950 - __main__ - INFO - Using custom dual-group optimizer with sophisticated LR scheduling
2025-09-19 06:56:40,951 - lr_scheduler - INFO - Parameter groups created:
2025-09-19 06:56:40,951 - lr_scheduler - INFO -   Base parameters: 199 tensors
2025-09-19 06:56:40,951 - lr_scheduler - INFO -   Head parameters: 4 tensors
2025-09-19 06:56:40,951 - lr_scheduler - INFO - Dual group optimizer created:
2025-09-19 06:56:40,951 - lr_scheduler - INFO -   Base LR: 2.00e-05
2025-09-19 06:56:40,951 - lr_scheduler - INFO -   Head LR: 2.00e-05 (1.0x multiplier)
2025-09-19 06:56:40,951 - __main__ - INFO - Precision summary -> bf16=True, fp16=False, tf32=True
2025-09-19 06:56:40,976 - __main__ - INFO - Early stopping enabled: patience=3, min_delta=0.01, post_resample_grace=2
2025-09-19 06:56:40,976 - lr_scheduler - INFO - PyTorch LambdaLR scheduler created:
2025-09-19 06:56:40,976 - lr_scheduler - INFO -   Base LR: 2.00e-05
2025-09-19 06:56:40,976 - lr_scheduler - INFO -   Head LR multiplier: 1.0x
2025-09-19 06:56:40,976 - lr_scheduler - INFO -   Multiplier converges to 1.0 at epoch 1
2025-09-19 06:56:40,976 - lr_scheduler - INFO -   Warmup steps: 57 (10.0%)
2025-09-19 06:56:40,976 - lr_scheduler - INFO -   Total steps: 570
2025-09-19 06:56:40,976 - lr_scheduler - INFO -   Min LR: 1.00e-07
2025-09-19 06:56:40,976 - lr_scheduler - INFO -   Scheduler type: Linear
2025-09-19 06:56:40,976 - __main__ - INFO - PyTorch LambdaLR scheduler created with 570 total steps, 57 steps/epoch
2025-09-19 06:56:40,983 - __main__ - INFO - Training setup:
2025-09-19 06:56:40,983 - __main__ - INFO -   - Train samples: 4060
2025-09-19 06:56:40,983 - __main__ - INFO -   - Test samples: 980
2025-09-19 06:56:40,983 - __main__ - INFO -   - Batch size: 24
2025-09-19 06:56:40,983 - __main__ - INFO -   - Gradient accumulation: 3
2025-09-19 06:56:40,983 - __main__ - INFO -   - Effective batch size: 72
2025-09-19 06:56:40,983 - __main__ - INFO -   - Steps per epoch: 57
2025-09-19 06:56:40,983 - __main__ - INFO -   - Total epochs: 10
2025-09-19 06:56:40,983 - __main__ - INFO -   - Estimated total steps: 570
2025-09-19 06:56:40,983 - __main__ - INFO - Performing initial evaluation to establish baseline...
2025-09-19 06:56:57,130 - __main__ - INFO - Evaluation - Epoch 0, Step 0: eval_loss=0.4904, eval_accuracy=0.627, Elapsed: 0.0s
2025-09-19 06:56:57,131 - __main__ - INFO - Starting training...
2025-09-19 06:56:57,578 - __main__ - INFO - Using stratified batch sampling for training
2025-09-19 06:56:57,579 - __main__ - INFO - Stratified batching: 7 subgenres, 2 guaranteed per subgenre, 10 random slots per batch
2025-09-19 06:56:57,587 - __main__ - INFO - Training started at 2025-09-19 06:56:57
2025-09-19 06:56:57,587 - __main__ - INFO - Epoch 0: Using margin 0.500
{'eval_accuracy': 0.6265306122448979, 'eval_loss': 0.490428626537323}
{'loss': 0.3614, 'grad_norm': 2.302069664001465, 'learning_rate': 1.9649122807017544e-05, 'epoch': 0.9882352941176471}
2025-09-19 07:00:10,162 - __main__ - INFO - Evaluation - Epoch 0.9882352941176471, Step 56: eval_loss=0.2400, eval_accuracy=0.800, Elapsed: 3m 12.6s
2025-09-19 07:00:10,162 - __main__ - INFO - Epoch 0: Using margin 0.500
{'eval_accuracy': 0.8, 'eval_loss': 0.24003788828849792, 'epoch': 0.9882352941176471}
{'loss': 0.112, 'grad_norm': 1.352528691291809, 'learning_rate': 1.7855750487329438e-05, 'epoch': 1.988235294117647}
2025-09-19 07:03:19,180 - __main__ - INFO - Evaluation - Epoch 1.988235294117647, Step 112: eval_loss=0.2103, eval_accuracy=0.822, Elapsed: 6m 21.6s
2025-09-19 07:03:19,181 - __main__ - INFO - Epoch 1: Using margin 0.500
{'eval_accuracy': 0.8224489795918367, 'eval_loss': 0.21025963127613068, 'epoch': 1.988235294117647}
{'loss': 0.0503, 'grad_norm': 0.5179017186164856, 'learning_rate': 1.5672514619883042e-05, 'epoch': 2.988235294117647}
2025-09-19 07:06:27,230 - __main__ - INFO - Evaluation - Epoch 2.988235294117647, Step 168: eval_loss=0.2177, eval_accuracy=0.818, Elapsed: 9m 29.6s
2025-09-19 07:06:27,231 - __main__ - INFO - Epoch 2: Using margin 0.500
{'eval_accuracy': 0.8183673469387756, 'eval_loss': 0.21769502758979797, 'epoch': 2.988235294117647}
{'loss': 0.0354, 'grad_norm': 0.819814920425415, 'learning_rate': 1.348927875243665e-05, 'epoch': 3.988235294117647}
2025-09-19 07:09:35,450 - __main__ - INFO - Evaluation - Epoch 3.988235294117647, Step 224: eval_loss=0.2169, eval_accuracy=0.814, Elapsed: 12m 37.9s
2025-09-19 07:09:35,450 - __main__ - INFO - Epoch 3: Using margin 0.500
{'eval_accuracy': 0.8142857142857143, 'eval_loss': 0.21685825288295746, 'epoch': 3.988235294117647}
{'loss': 0.0251, 'grad_norm': 0.9830061197280884, 'learning_rate': 1.1306042884990255e-05, 'epoch': 4.988235294117647}
2025-09-19 07:12:43,253 - __main__ - INFO - Evaluation - Epoch 4.988235294117647, Step 280: eval_loss=0.2140, eval_accuracy=0.816, Elapsed: 15m 45.7s
2025-09-19 07:12:43,254 - __main__ - INFO - Epoch 4: Using margin 0.500
{'eval_accuracy': 0.8163265306122449, 'eval_loss': 0.2139856219291687, 'epoch': 4.988235294117647}
{'loss': 0.0147, 'grad_norm': 0.7636487483978271, 'learning_rate': 9.12280701754386e-06, 'epoch': 5.988235294117647}
2025-09-19 07:15:51,066 - __main__ - INFO - Evaluation - Epoch 5.988235294117647, Step 336: eval_loss=0.2207, eval_accuracy=0.813, Elapsed: 18m 53.5s
2025-09-19 07:15:51,067 - __main__ - INFO - Epoch 5: Using margin 0.500
{'eval_accuracy': 0.813265306122449, 'eval_loss': 0.2206578403711319, 'epoch': 5.988235294117647}
{'loss': 0.0108, 'grad_norm': 0.6902980804443359, 'learning_rate': 6.939571150097466e-06, 'epoch': 6.988235294117647}
2025-09-19 07:18:58,694 - __main__ - INFO - Evaluation - Epoch 6.988235294117647, Step 392: eval_loss=0.2029, eval_accuracy=0.828, Elapsed: 22m 1.1s
2025-09-19 07:18:58,695 - __main__ - INFO - Epoch 6: Using margin 0.500
{'eval_accuracy': 0.8275510204081633, 'eval_loss': 0.2028552144765854, 'epoch': 6.988235294117647}
{'loss': 0.0056, 'grad_norm': 0.7508983612060547, 'learning_rate': 4.756335282651072e-06, 'epoch': 7.988235294117647}
2025-09-19 07:22:06,405 - __main__ - INFO - Evaluation - Epoch 7.988235294117647, Step 448: eval_loss=0.2128, eval_accuracy=0.820, Elapsed: 25m 8.8s
2025-09-19 07:22:06,406 - __main__ - INFO - Epoch 7: Using margin 0.500
{'eval_accuracy': 0.8204081632653061, 'eval_loss': 0.21280533075332642, 'epoch': 7.988235294117647}
{'loss': 0.0034, 'grad_norm': 0.0, 'learning_rate': 2.5730994152046784e-06, 'epoch': 8.988235294117647}
2025-09-19 07:25:14,196 - __main__ - INFO - Evaluation - Epoch 8.988235294117647, Step 504: eval_loss=0.2130, eval_accuracy=0.821, Elapsed: 28m 16.6s
2025-09-19 07:25:14,197 - __main__ - INFO - Epoch 8: Using margin 0.500
{'eval_accuracy': 0.8214285714285714, 'eval_loss': 0.2129896730184555, 'epoch': 8.988235294117647}
{'loss': 0.0024, 'grad_norm': 0.31976673007011414, 'learning_rate': 3.898635477582846e-07, 'epoch': 9.988235294117647}
2025-09-19 07:28:20,270 - __main__ - INFO - Evaluation - Epoch 9.988235294117647, Step 560: eval_loss=0.2121, eval_accuracy=0.817, Elapsed: 31m 22.7s
2025-09-19 07:28:20,274 - __main__ - INFO - Training completed! Total training time: 31m 22.7s
2025-09-19 07:28:20,274 - __main__ - INFO - Training ended at 2025-09-19 07:28:20
2025-09-19 07:28:20,274 - __main__ - INFO - [EarlyStopping] Training completed normally with final best accuracy: -inf
2025-09-19 07:28:20,274 - __main__ - INFO - Saving model and artifacts...
2025-09-19 07:28:21,568 - __main__ - INFO - Model saved to run_20250919_065638/model.safetensors
2025-09-19 07:28:21,570 - __main__ - INFO - Configuration saved to run_20250919_065638/config.json
2025-09-19 07:28:21,591 - __main__ - INFO - Splits saved to run_20250919_065638/splits.json
2025-09-19 07:28:21,591 - __main__ - INFO - All training artifacts saved to run_20250919_065638
2025-09-19 07:28:21,591 - __main__ - INFO - Training completed successfully! Training time: 31m 23.1s | Results saved to: run_20250919_065638
{'eval_accuracy': 0.8173469387755102, 'eval_loss': 0.21213485300540924, 'epoch': 9.988235294117647}
{'train_runtime': 1882.6846, 'train_samples_per_second': 21.565, 'train_steps_per_second': 0.297, 'train_loss': 0.062093646292175564, 'epoch': 9.988235294117647}
[INFO] Collecting artifacts to /homes/nnebeling/thesis/runs/ast-a40.162941 ...
  -> copying run_20250919_065638
  -> skipping ast_triplet_output (empty directory)
  -> skipping logs (empty directory)
[DONE] Everything copied to: /homes/nnebeling/thesis/runs/ast-a40.162941
Job runtime: 1919 seconds (00:31:59)
