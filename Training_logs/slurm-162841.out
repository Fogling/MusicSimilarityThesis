[INFO] SLURM_JOB_TMP is: /local/slurmjobs/162841
[INFO] Using GPU: 0
[INFO] Staging archive to node SSD...
'/homes/nnebeling/thesis/precomputed_AST_7G.zip' -> '/local/slurmjobs/162841/precomputed_AST_7G.zip'
[INFO] Unpacking on SSD...
[OK] Unpacked. Top-level contents:
.
precomputed_AST_7G
precomputed_AST_7G/Chill House
precomputed_AST_7G/Zyzz Music
precomputed_AST_7G/Emotional Techno
precomputed_AST_7G/Party House
precomputed_AST_7G/Chiller vibe goa
precomputed_AST_7G/Dark Techno
precomputed_AST_7G/Party Goa
[INFO] Starting training...
2025-09-18 12:04:52,013 - __main__ - INFO - Loading configuration...
2025-09-18 12:04:52,015 - __main__ - INFO - set_float32_matmul_precision=high
2025-09-18 12:04:52,015 - __main__ - INFO - TF32: matmul=True, cudnn=True
2025-09-18 12:04:52,408 - __main__ - INFO - Experiment: Best Parameter Setup, Optimizing dataset size
2025-09-18 12:04:52,408 - __main__ - INFO - Description: Trying 1x5
2025-09-18 12:04:52,414 - __main__ - INFO - Random seeds set to 13
2025-09-18 12:04:52,414 - __main__ - INFO - Loading data splits...
2025-09-18 12:04:52,414 - __main__ - INFO - Generating train/test splits from preprocessed features
2025-09-18 12:04:52,414 - __main__ - INFO - Generating track-level splits to prevent data leakage...
2025-09-18 12:04:52,417 - __main__ - INFO - Subgenre Chill House: 81 tracks, 243 chunks total
2025-09-18 12:04:52,418 - __main__ - INFO - Subgenre Chiller vibe goa: 54 tracks, 162 chunks total
2025-09-18 12:04:52,419 - __main__ - INFO - Subgenre Dark Techno: 86 tracks, 258 chunks total
2025-09-18 12:04:52,421 - __main__ - INFO - Subgenre Emotional Techno: 75 tracks, 225 chunks total
2025-09-18 12:04:52,422 - __main__ - INFO - Subgenre Party Goa: 62 tracks, 186 chunks total
2025-09-18 12:04:52,423 - __main__ - INFO - Subgenre Party House: 69 tracks, 207 chunks total
2025-09-18 12:04:52,425 - __main__ - INFO - Subgenre Zyzz Music: 77 tracks, 231 chunks total
2025-09-18 12:04:52,425 - __main__ - INFO - Subgenre Chill House: 65 train tracks, 16 test tracks
2025-09-18 12:04:52,425 - __main__ - INFO - Subgenre Chiller vibe goa: 44 train tracks, 10 test tracks
2025-09-18 12:04:52,425 - __main__ - INFO - Subgenre Dark Techno: 69 train tracks, 17 test tracks
2025-09-18 12:04:52,425 - __main__ - INFO - Subgenre Emotional Techno: 60 train tracks, 15 test tracks
2025-09-18 12:04:52,425 - __main__ - INFO - Subgenre Party Goa: 50 train tracks, 12 test tracks
2025-09-18 12:04:52,425 - __main__ - INFO - Subgenre Party House: 56 train tracks, 13 test tracks
2025-09-18 12:04:52,425 - __main__ - INFO - Subgenre Zyzz Music: 62 train tracks, 15 test tracks
2025-09-18 12:04:52,425 - __main__ - INFO - Generating training triplets from train tracks...
2025-09-18 12:04:52,425 - __main__ - INFO - Train triplet generation config:
2025-09-18 12:04:52,425 - __main__ - INFO -   Max positive tracks per anchor: 5
2025-09-18 12:04:52,425 - __main__ - INFO -   Triplets per positive track: 1
2025-09-18 12:04:52,425 - __main__ - INFO -   Expected triplets per anchor: ~5
2025-09-18 12:04:52,428 - __main__ - INFO - Train - Subgenre Chill House: 975 triplets from 65 tracks
2025-09-18 12:04:52,430 - __main__ - INFO - Train - Subgenre Chiller vibe goa: 660 triplets from 44 tracks
2025-09-18 12:04:52,432 - __main__ - INFO - Train - Subgenre Dark Techno: 1035 triplets from 69 tracks
2025-09-18 12:04:52,434 - __main__ - INFO - Train - Subgenre Emotional Techno: 900 triplets from 60 tracks
2025-09-18 12:04:52,436 - __main__ - INFO - Train - Subgenre Party Goa: 750 triplets from 50 tracks
2025-09-18 12:04:52,438 - __main__ - INFO - Train - Subgenre Party House: 840 triplets from 56 tracks
2025-09-18 12:04:52,441 - __main__ - INFO - Train - Subgenre Zyzz Music: 930 triplets from 62 tracks
2025-09-18 12:04:52,441 - __main__ - INFO - Generating test triplets from test tracks...
2025-09-18 12:04:52,442 - __main__ - INFO - Test triplet generation config:
2025-09-18 12:04:52,442 - __main__ - INFO -   Max positive tracks per anchor: 5
2025-09-18 12:04:52,442 - __main__ - INFO -   Triplets per positive track: 1
2025-09-18 12:04:52,442 - __main__ - INFO -   Expected triplets per anchor: ~5
2025-09-18 12:04:52,442 - __main__ - INFO - Test - Subgenre Chill House: 240 triplets from 16 tracks
2025-09-18 12:04:52,443 - __main__ - INFO - Test - Subgenre Chiller vibe goa: 150 triplets from 10 tracks
2025-09-18 12:04:52,443 - __main__ - INFO - Test - Subgenre Dark Techno: 255 triplets from 17 tracks
2025-09-18 12:04:52,444 - __main__ - INFO - Test - Subgenre Emotional Techno: 225 triplets from 15 tracks
2025-09-18 12:04:52,444 - __main__ - INFO - Test - Subgenre Party Goa: 180 triplets from 12 tracks
2025-09-18 12:04:52,445 - __main__ - INFO - Test - Subgenre Party House: 195 triplets from 13 tracks
2025-09-18 12:04:52,445 - __main__ - INFO - Test - Subgenre Zyzz Music: 225 triplets from 15 tracks
2025-09-18 12:04:52,445 - __main__ - INFO - ✓ NO DATA LEAKAGE: 406 unique train tracks, 98 unique test tracks
2025-09-18 12:04:52,445 - __main__ - INFO - Total: 6090 train triplets, 1470 test triplets
2025-09-18 12:04:52,446 - __main__ - INFO - Creating datasets...
2025-09-18 12:04:52,519 - __main__ - INFO - Initialized dataset (train) with 6090 triplets (resample_train_samples=False)
2025-09-18 12:04:52,536 - __main__ - INFO - Initialized dataset (test) with 1470 triplets (resample_train_samples=False)
2025-09-18 12:04:52,536 - __main__ - INFO - Initializing model...
2025-09-18 12:04:52,536 - __main__ - INFO - Using device: cuda
2025-09-18 12:04:52,536 - __main__ - INFO - Loading pretrained model: MIT/ast-finetuned-audioset-10-10-0.4593
2025-09-18 12:04:54,578 - __main__ - INFO - MLP Projection Head Architecture: 768 -> 512 -> 128
2025-09-18 12:04:54,578 - __main__ - INFO -   Activation: relu, Dropout: 0.15
2025-09-18 12:04:54,578 - __main__ - INFO -   Total parameters: 459,392
2025-09-18 12:04:54,579 - __main__ - INFO - Model initialized with projection to 128D
2025-09-18 12:04:54,579 - __main__ - INFO - Margin scheduling: 0.5 → 0.5 over 1 epochs
2025-09-18 12:04:54,579 - __main__ - INFO - Negative mining: none
2025-09-18 12:04:54,872 - __main__ - INFO - Using custom dual-group optimizer with sophisticated LR scheduling
2025-09-18 12:04:54,873 - lr_scheduler - INFO - Parameter groups created:
2025-09-18 12:04:54,873 - lr_scheduler - INFO -   Base parameters: 199 tensors
2025-09-18 12:04:54,873 - lr_scheduler - INFO -   Head parameters: 4 tensors
2025-09-18 12:04:54,874 - lr_scheduler - INFO - Dual group optimizer created:
2025-09-18 12:04:54,874 - lr_scheduler - INFO -   Base LR: 2.00e-05
2025-09-18 12:04:54,874 - lr_scheduler - INFO -   Head LR: 2.00e-05 (1.0x multiplier)
2025-09-18 12:04:54,874 - __main__ - INFO - Precision summary -> bf16=True, fp16=False, tf32=True
2025-09-18 12:04:54,901 - __main__ - INFO - Early stopping disabled
2025-09-18 12:04:54,901 - lr_scheduler - INFO - PyTorch LambdaLR scheduler created:
2025-09-18 12:04:54,901 - lr_scheduler - INFO -   Base LR: 2.00e-05
2025-09-18 12:04:54,901 - lr_scheduler - INFO -   Head LR multiplier: 1.0x
2025-09-18 12:04:54,901 - lr_scheduler - INFO -   Multiplier converges to 1.0 at epoch 1
2025-09-18 12:04:54,901 - lr_scheduler - INFO -   Warmup steps: 42 (9.9%)
2025-09-18 12:04:54,901 - lr_scheduler - INFO -   Total steps: 425
2025-09-18 12:04:54,901 - lr_scheduler - INFO -   Min LR: 1.00e-07
2025-09-18 12:04:54,902 - lr_scheduler - INFO -   Scheduler type: Linear
2025-09-18 12:04:54,902 - __main__ - INFO - PyTorch LambdaLR scheduler created with 425 total steps, 85 steps/epoch
2025-09-18 12:04:54,916 - __main__ - INFO - Training setup:
2025-09-18 12:04:54,916 - __main__ - INFO -   - Train samples: 6090
2025-09-18 12:04:54,916 - __main__ - INFO -   - Test samples: 1470
2025-09-18 12:04:54,916 - __main__ - INFO -   - Batch size: 24
2025-09-18 12:04:54,916 - __main__ - INFO -   - Gradient accumulation: 3
2025-09-18 12:04:54,916 - __main__ - INFO -   - Effective batch size: 72
2025-09-18 12:04:54,917 - __main__ - INFO -   - Steps per epoch: 85
2025-09-18 12:04:54,917 - __main__ - INFO -   - Total epochs: 5
2025-09-18 12:04:54,917 - __main__ - INFO -   - Estimated total steps: 425
2025-09-18 12:04:54,917 - __main__ - INFO - Performing initial evaluation to establish baseline...
2025-09-18 12:05:18,391 - __main__ - INFO - Evaluation - Epoch 0, Step 0: eval_loss=0.4857, eval_accuracy=0.624, Elapsed: 0.0s
2025-09-18 12:05:18,392 - __main__ - INFO - Starting training...
2025-09-18 12:05:18,562 - __main__ - INFO - Using stratified batch sampling for training
2025-09-18 12:05:18,563 - __main__ - INFO - Stratified batching: 7 subgenres, 2 guaranteed per subgenre, 10 random slots per batch
2025-09-18 12:05:18,570 - __main__ - INFO - Training started at 2025-09-18 12:05:18
2025-09-18 12:05:18,570 - __main__ - INFO - Epoch 0: Using margin 0.500
{'eval_accuracy': 0.6244897959183674, 'eval_loss': 0.48566797375679016}
{'loss': 0.3108, 'grad_norm': 1.749688982963562, 'learning_rate': 1.7754569190600522e-05, 'epoch': 1.0}
2025-09-18 12:10:06,323 - __main__ - INFO - Evaluation - Epoch 1.0, Step 85: eval_loss=0.2351, eval_accuracy=0.798, Elapsed: 4m 47.8s
2025-09-18 12:10:08,219 - __main__ - INFO - Epoch 1: Using margin 0.500
{'eval_accuracy': 0.7979591836734694, 'eval_loss': 0.23509937524795532, 'epoch': 1.0}
{'loss': 0.1075, 'grad_norm': 1.253474235534668, 'learning_rate': 1.3315926892950393e-05, 'epoch': 2.0}
2025-09-18 12:14:52,110 - __main__ - INFO - Evaluation - Epoch 2.0, Step 170: eval_loss=0.1891, eval_accuracy=0.841, Elapsed: 9m 33.5s
2025-09-18 12:14:55,758 - __main__ - INFO - Epoch 2: Using margin 0.500
{'eval_accuracy': 0.8414965986394558, 'eval_loss': 0.18913325667381287, 'epoch': 2.0}
{'loss': 0.0565, 'grad_norm': 0.5357592105865479, 'learning_rate': 8.877284595300261e-06, 'epoch': 3.0}
2025-09-18 12:19:38,515 - __main__ - INFO - Evaluation - Epoch 3.0, Step 255: eval_loss=0.1835, eval_accuracy=0.845, Elapsed: 14m 19.9s
2025-09-18 12:19:40,441 - __main__ - INFO - Epoch 3: Using margin 0.500
{'eval_accuracy': 0.8448979591836735, 'eval_loss': 0.18350379168987274, 'epoch': 3.0}
{'loss': 0.0384, 'grad_norm': 0.4077286720275879, 'learning_rate': 4.4386422976501306e-06, 'epoch': 4.0}
2025-09-18 12:24:22,748 - __main__ - INFO - Evaluation - Epoch 4.0, Step 340: eval_loss=0.1834, eval_accuracy=0.865, Elapsed: 19m 4.2s
2025-09-18 12:24:25,107 - __main__ - INFO - Epoch 4: Using margin 0.500
{'eval_accuracy': 0.8653061224489796, 'eval_loss': 0.18338970839977264, 'epoch': 4.0}
{'loss': 0.0333, 'grad_norm': 0.534989058971405, 'learning_rate': 2.610966057441244e-07, 'epoch': 4.94488188976378}
2025-09-18 12:28:53,329 - __main__ - INFO - Evaluation - Epoch 4.94488188976378, Step 420: eval_loss=0.1901, eval_accuracy=0.852, Elapsed: 23m 34.8s
2025-09-18 12:28:55,575 - __main__ - INFO - Training completed! Total training time: 23m 37.0s
2025-09-18 12:28:55,575 - __main__ - INFO - Training ended at 2025-09-18 12:28:55
2025-09-18 12:28:55,575 - __main__ - INFO - Saving model and artifacts...
2025-09-18 12:28:56,952 - __main__ - INFO - Model saved to run_20250918_120452/model.safetensors
2025-09-18 12:28:56,954 - __main__ - INFO - Configuration saved to run_20250918_120452/config.json
2025-09-18 12:28:56,984 - __main__ - INFO - Splits saved to run_20250918_120452/splits.json
2025-09-18 12:28:56,984 - __main__ - INFO - All training artifacts saved to run_20250918_120452
2025-09-18 12:28:56,984 - __main__ - INFO - Training completed successfully! Training time: 23m 37.2s | Results saved to: run_20250918_120452
{'eval_accuracy': 0.8517006802721089, 'eval_loss': 0.1900838166475296, 'epoch': 4.94488188976378}
{'train_runtime': 1417.0036, 'train_samples_per_second': 21.489, 'train_steps_per_second': 0.296, 'train_loss': 0.11022128547940935, 'epoch': 4.94488188976378}
[INFO] Collecting artifacts to /homes/nnebeling/thesis/runs/ast-a40.162841 ...
  -> copying run_20250918_120452
  -> skipping ast_triplet_output (empty directory)
  -> skipping logs (empty directory)
[DONE] Everything copied to: /homes/nnebeling/thesis/runs/ast-a40.162841
Job runtime: 1469 seconds (00:24:29)
