[INFO] SLURM_JOB_TMP is: /local/slurmjobs/162942
[INFO] Using GPU: 0
[INFO] Staging archive to node SSD...
'/homes/nnebeling/thesis/precomputed_7G_2Chunk.zip' -> '/local/slurmjobs/162942/precomputed_7G_2Chunk.zip'
[INFO] Unpacking on SSD...
[OK] Unpacked. Top-level contents:
.
precomputed_7G_2Chunk
precomputed_7G_2Chunk/Chill House
precomputed_7G_2Chunk/Zyzz Music
precomputed_7G_2Chunk/Emotional Techno
precomputed_7G_2Chunk/Party House
precomputed_7G_2Chunk/Chiller vibe goa
precomputed_7G_2Chunk/Dark Techno
precomputed_7G_2Chunk/Party Goa
[INFO] Starting training...
2025-09-19 07:28:37,222 - __main__ - INFO - Loading configuration...
2025-09-19 07:28:37,225 - __main__ - INFO - set_float32_matmul_precision=high
2025-09-19 07:28:37,225 - __main__ - INFO - TF32: matmul=True, cudnn=True
2025-09-19 07:28:37,630 - __main__ - INFO - Experiment: Testing 2 chunks per track
2025-09-19 07:28:37,630 - __main__ - INFO - Description: Dataset size 1x6
2025-09-19 07:28:37,632 - __main__ - INFO - Random seeds set to 23
2025-09-19 07:28:37,632 - __main__ - INFO - Loading data splits...
2025-09-19 07:28:37,632 - __main__ - INFO - Generating train/test splits from preprocessed features
2025-09-19 07:28:37,632 - __main__ - INFO - Generating track-level splits to prevent data leakage...
2025-09-19 07:28:37,633 - __main__ - INFO - Subgenre Chill House: 81 tracks, 162 chunks total
2025-09-19 07:28:37,634 - __main__ - INFO - Subgenre Chiller vibe goa: 54 tracks, 108 chunks total
2025-09-19 07:28:37,635 - __main__ - INFO - Subgenre Dark Techno: 86 tracks, 172 chunks total
2025-09-19 07:28:37,636 - __main__ - INFO - Subgenre Emotional Techno: 75 tracks, 150 chunks total
2025-09-19 07:28:37,637 - __main__ - INFO - Subgenre Party Goa: 62 tracks, 124 chunks total
2025-09-19 07:28:37,638 - __main__ - INFO - Subgenre Party House: 69 tracks, 138 chunks total
2025-09-19 07:28:37,639 - __main__ - INFO - Subgenre Zyzz Music: 77 tracks, 154 chunks total
2025-09-19 07:28:37,639 - __main__ - INFO - Subgenre Chill House: 65 train tracks, 16 test tracks
2025-09-19 07:28:37,639 - __main__ - INFO - Subgenre Chiller vibe goa: 44 train tracks, 10 test tracks
2025-09-19 07:28:37,639 - __main__ - INFO - Subgenre Dark Techno: 69 train tracks, 17 test tracks
2025-09-19 07:28:37,639 - __main__ - INFO - Subgenre Emotional Techno: 60 train tracks, 15 test tracks
2025-09-19 07:28:37,639 - __main__ - INFO - Subgenre Party Goa: 50 train tracks, 12 test tracks
2025-09-19 07:28:37,639 - __main__ - INFO - Subgenre Party House: 56 train tracks, 13 test tracks
2025-09-19 07:28:37,640 - __main__ - INFO - Subgenre Zyzz Music: 62 train tracks, 15 test tracks
2025-09-19 07:28:37,640 - __main__ - INFO - Generating training triplets from train tracks...
2025-09-19 07:28:37,640 - __main__ - INFO - Train triplet generation config:
2025-09-19 07:28:37,640 - __main__ - INFO -   Max positive tracks per anchor: 6
2025-09-19 07:28:37,640 - __main__ - INFO -   Triplets per positive track: 1
2025-09-19 07:28:37,640 - __main__ - INFO -   Expected triplets per anchor: ~6
2025-09-19 07:28:37,642 - __main__ - INFO - Train - Subgenre Chill House: 780 triplets from 65 tracks
2025-09-19 07:28:37,643 - __main__ - INFO - Train - Subgenre Chiller vibe goa: 528 triplets from 44 tracks
2025-09-19 07:28:37,645 - __main__ - INFO - Train - Subgenre Dark Techno: 828 triplets from 69 tracks
2025-09-19 07:28:37,647 - __main__ - INFO - Train - Subgenre Emotional Techno: 720 triplets from 60 tracks
2025-09-19 07:28:37,648 - __main__ - INFO - Train - Subgenre Party Goa: 600 triplets from 50 tracks
2025-09-19 07:28:37,650 - __main__ - INFO - Train - Subgenre Party House: 672 triplets from 56 tracks
2025-09-19 07:28:37,652 - __main__ - INFO - Train - Subgenre Zyzz Music: 744 triplets from 62 tracks
2025-09-19 07:28:37,652 - __main__ - INFO - Generating test triplets from test tracks...
2025-09-19 07:28:37,652 - __main__ - INFO - Test triplet generation config:
2025-09-19 07:28:37,652 - __main__ - INFO -   Max positive tracks per anchor: 6
2025-09-19 07:28:37,652 - __main__ - INFO -   Triplets per positive track: 1
2025-09-19 07:28:37,652 - __main__ - INFO -   Expected triplets per anchor: ~6
2025-09-19 07:28:37,652 - __main__ - INFO - Test - Subgenre Chill House: 192 triplets from 16 tracks
2025-09-19 07:28:37,653 - __main__ - INFO - Test - Subgenre Chiller vibe goa: 120 triplets from 10 tracks
2025-09-19 07:28:37,653 - __main__ - INFO - Test - Subgenre Dark Techno: 204 triplets from 17 tracks
2025-09-19 07:28:37,654 - __main__ - INFO - Test - Subgenre Emotional Techno: 180 triplets from 15 tracks
2025-09-19 07:28:37,655 - __main__ - INFO - Test - Subgenre Party Goa: 144 triplets from 12 tracks
2025-09-19 07:28:37,655 - __main__ - INFO - Test - Subgenre Party House: 156 triplets from 13 tracks
2025-09-19 07:28:37,655 - __main__ - INFO - Test - Subgenre Zyzz Music: 180 triplets from 15 tracks
2025-09-19 07:28:37,656 - __main__ - INFO - ✓ NO DATA LEAKAGE: 406 unique train tracks, 98 unique test tracks
2025-09-19 07:28:37,656 - __main__ - INFO - Total: 4872 train triplets, 1176 test triplets
2025-09-19 07:28:37,656 - __main__ - INFO - Creating datasets...
2025-09-19 07:28:37,712 - __main__ - INFO - Initialized dataset (train) with 4872 triplets (resample_train_samples=False)
2025-09-19 07:28:37,725 - __main__ - INFO - Initialized dataset (test) with 1176 triplets (resample_train_samples=False)
2025-09-19 07:28:37,725 - __main__ - INFO - Initializing model...
2025-09-19 07:28:37,725 - __main__ - INFO - Using device: cuda
2025-09-19 07:28:37,725 - __main__ - INFO - Loading pretrained model: MIT/ast-finetuned-audioset-10-10-0.4593
2025-09-19 07:28:39,760 - __main__ - INFO - MLP Projection Head Architecture: 768 -> 512 -> 128
2025-09-19 07:28:39,760 - __main__ - INFO -   Activation: relu, Dropout: 0.15
2025-09-19 07:28:39,760 - __main__ - INFO -   Total parameters: 459,392
2025-09-19 07:28:39,760 - __main__ - INFO - Model initialized with projection to 128D
2025-09-19 07:28:39,760 - __main__ - INFO - Margin scheduling: 0.5 → 0.5 over 1 epochs
2025-09-19 07:28:39,760 - __main__ - INFO - Negative mining: none
2025-09-19 07:28:40,015 - __main__ - INFO - Using custom dual-group optimizer with sophisticated LR scheduling
2025-09-19 07:28:40,016 - lr_scheduler - INFO - Parameter groups created:
2025-09-19 07:28:40,016 - lr_scheduler - INFO -   Base parameters: 199 tensors
2025-09-19 07:28:40,016 - lr_scheduler - INFO -   Head parameters: 4 tensors
2025-09-19 07:28:40,016 - lr_scheduler - INFO - Dual group optimizer created:
2025-09-19 07:28:40,016 - lr_scheduler - INFO -   Base LR: 2.00e-05
2025-09-19 07:28:40,016 - lr_scheduler - INFO -   Head LR: 2.00e-05 (1.0x multiplier)
2025-09-19 07:28:40,016 - __main__ - INFO - Precision summary -> bf16=True, fp16=False, tf32=True
2025-09-19 07:28:40,042 - __main__ - INFO - Early stopping enabled: patience=3, min_delta=0.01, post_resample_grace=2
2025-09-19 07:28:40,042 - lr_scheduler - INFO - PyTorch LambdaLR scheduler created:
2025-09-19 07:28:40,042 - lr_scheduler - INFO -   Base LR: 2.00e-05
2025-09-19 07:28:40,042 - lr_scheduler - INFO -   Head LR multiplier: 1.0x
2025-09-19 07:28:40,042 - lr_scheduler - INFO -   Multiplier converges to 1.0 at epoch 1
2025-09-19 07:28:40,042 - lr_scheduler - INFO -   Warmup steps: 68 (10.0%)
2025-09-19 07:28:40,042 - lr_scheduler - INFO -   Total steps: 680
2025-09-19 07:28:40,042 - lr_scheduler - INFO -   Min LR: 1.00e-07
2025-09-19 07:28:40,042 - lr_scheduler - INFO -   Scheduler type: Linear
2025-09-19 07:28:40,042 - __main__ - INFO - PyTorch LambdaLR scheduler created with 680 total steps, 68 steps/epoch
2025-09-19 07:28:40,050 - __main__ - INFO - Training setup:
2025-09-19 07:28:40,050 - __main__ - INFO -   - Train samples: 4872
2025-09-19 07:28:40,050 - __main__ - INFO -   - Test samples: 1176
2025-09-19 07:28:40,050 - __main__ - INFO -   - Batch size: 24
2025-09-19 07:28:40,050 - __main__ - INFO -   - Gradient accumulation: 3
2025-09-19 07:28:40,050 - __main__ - INFO -   - Effective batch size: 72
2025-09-19 07:28:40,050 - __main__ - INFO -   - Steps per epoch: 68
2025-09-19 07:28:40,050 - __main__ - INFO -   - Total epochs: 10
2025-09-19 07:28:40,050 - __main__ - INFO -   - Estimated total steps: 680
2025-09-19 07:28:40,050 - __main__ - INFO - Performing initial evaluation to establish baseline...
2025-09-19 07:28:58,981 - __main__ - INFO - Evaluation - Epoch 0, Step 0: eval_loss=0.4914, eval_accuracy=0.599, Elapsed: 0.0s
2025-09-19 07:28:58,982 - __main__ - INFO - Starting training...
2025-09-19 07:28:59,173 - __main__ - INFO - Using stratified batch sampling for training
2025-09-19 07:28:59,174 - __main__ - INFO - Stratified batching: 7 subgenres, 2 guaranteed per subgenre, 10 random slots per batch
2025-09-19 07:28:59,181 - __main__ - INFO - Training started at 2025-09-19 07:28:59
2025-09-19 07:28:59,181 - __main__ - INFO - Epoch 0: Using margin 0.500
{'eval_accuracy': 0.5994897959183674, 'eval_loss': 0.4913807511329651}
{'loss': 0.3411, 'grad_norm': 1.6941475868225098, 'learning_rate': 2e-05, 'epoch': 1.0}
2025-09-19 07:32:50,010 - __main__ - INFO - Evaluation - Epoch 1.0, Step 68: eval_loss=0.2251, eval_accuracy=0.822, Elapsed: 3m 50.8s
2025-09-19 07:32:50,011 - __main__ - INFO - Epoch 1: Using margin 0.500
{'eval_accuracy': 0.8222789115646258, 'eval_loss': 0.22506244480609894, 'epoch': 1.0}
{'loss': 0.0897, 'grad_norm': 1.2865921258926392, 'learning_rate': 1.7777777777777777e-05, 'epoch': 2.0}
2025-09-19 07:36:35,680 - __main__ - INFO - Evaluation - Epoch 2.0, Step 136: eval_loss=0.2095, eval_accuracy=0.831, Elapsed: 7m 36.5s
2025-09-19 07:36:35,681 - __main__ - INFO - Epoch 2: Using margin 0.500
{'eval_accuracy': 0.83078231292517, 'eval_loss': 0.20951718091964722, 'epoch': 2.0}
{'loss': 0.0447, 'grad_norm': 1.1478456258773804, 'learning_rate': 1.555555555555556e-05, 'epoch': 3.0}
2025-09-19 07:40:21,261 - __main__ - INFO - Evaluation - Epoch 3.0, Step 204: eval_loss=0.1954, eval_accuracy=0.835, Elapsed: 11m 22.1s
2025-09-19 07:40:21,262 - __main__ - INFO - Epoch 3: Using margin 0.500
{'eval_accuracy': 0.8350340136054422, 'eval_loss': 0.19538229703903198, 'epoch': 3.0}
{'loss': 0.032, 'grad_norm': 0.5395176410675049, 'learning_rate': 1.3333333333333337e-05, 'epoch': 4.0}
2025-09-19 07:44:06,261 - __main__ - INFO - Evaluation - Epoch 4.0, Step 272: eval_loss=0.1984, eval_accuracy=0.838, Elapsed: 15m 7.1s
2025-09-19 07:44:06,262 - __main__ - INFO - Epoch 4: Using margin 0.500
{'eval_accuracy': 0.8384353741496599, 'eval_loss': 0.19844010472297668, 'epoch': 4.0}
{'loss': 0.0238, 'grad_norm': 0.4906027913093567, 'learning_rate': 1.1111111111111113e-05, 'epoch': 5.0}
2025-09-19 07:47:51,929 - __main__ - INFO - Evaluation - Epoch 5.0, Step 340: eval_loss=0.1985, eval_accuracy=0.840, Elapsed: 18m 52.7s
2025-09-19 07:47:51,930 - __main__ - INFO - Epoch 5: Using margin 0.500
{'eval_accuracy': 0.8401360544217688, 'eval_loss': 0.19846385717391968, 'epoch': 5.0}
{'loss': 0.0134, 'grad_norm': 0.6198985576629639, 'learning_rate': 8.888888888888888e-06, 'epoch': 6.0}
2025-09-19 07:51:37,331 - __main__ - INFO - Evaluation - Epoch 6.0, Step 408: eval_loss=0.2065, eval_accuracy=0.830, Elapsed: 22m 38.1s
2025-09-19 07:51:37,332 - __main__ - INFO - Epoch 6: Using margin 0.500
{'eval_accuracy': 0.8299319727891157, 'eval_loss': 0.20649704337120056, 'epoch': 6.0}
{'loss': 0.0064, 'grad_norm': 0.4296036958694458, 'learning_rate': 6.666666666666668e-06, 'epoch': 7.0}
2025-09-19 07:55:22,569 - __main__ - INFO - Evaluation - Epoch 7.0, Step 476: eval_loss=0.2147, eval_accuracy=0.827, Elapsed: 26m 23.4s
2025-09-19 07:55:22,570 - __main__ - INFO - Epoch 7: Using margin 0.500
{'eval_accuracy': 0.8273809523809523, 'eval_loss': 0.21467076241970062, 'epoch': 7.0}
{'loss': 0.0033, 'grad_norm': 0.0, 'learning_rate': 4.444444444444444e-06, 'epoch': 8.0}
2025-09-19 07:59:07,733 - __main__ - INFO - Evaluation - Epoch 8.0, Step 544: eval_loss=0.2069, eval_accuracy=0.829, Elapsed: 30m 8.6s
2025-09-19 07:59:07,734 - __main__ - INFO - Epoch 8: Using margin 0.500
{'eval_accuracy': 0.8290816326530612, 'eval_loss': 0.20693466067314148, 'epoch': 8.0}
{'loss': 0.0017, 'grad_norm': 0.0, 'learning_rate': 2.2222222222222233e-06, 'epoch': 9.0}
2025-09-19 08:02:52,592 - __main__ - INFO - Evaluation - Epoch 9.0, Step 612: eval_loss=0.1969, eval_accuracy=0.833, Elapsed: 33m 53.4s
2025-09-19 08:02:52,593 - __main__ - INFO - Epoch 9: Using margin 0.500
{'eval_accuracy': 0.8333333333333334, 'eval_loss': 0.19686713814735413, 'epoch': 9.0}
{'loss': 0.0011, 'grad_norm': 0.27893495559692383, 'learning_rate': 3.267973856209161e-07, 'epoch': 9.857142857142858}
2025-09-19 08:06:08,178 - __main__ - INFO - Evaluation - Epoch 9.857142857142858, Step 670: eval_loss=0.2036, eval_accuracy=0.831, Elapsed: 37m 9.0s
2025-09-19 08:06:08,179 - __main__ - INFO - Training completed! Total training time: 37m 9.0s
2025-09-19 08:06:08,179 - __main__ - INFO - Training ended at 2025-09-19 08:06:08
2025-09-19 08:06:08,179 - __main__ - INFO - [EarlyStopping] Training completed normally with final best accuracy: -inf
2025-09-19 08:06:08,180 - __main__ - INFO - Saving model and artifacts...
2025-09-19 08:06:09,016 - __main__ - INFO - Model saved to run_20250919_072837/model.safetensors
2025-09-19 08:06:09,017 - __main__ - INFO - Configuration saved to run_20250919_072837/config.json
2025-09-19 08:06:09,039 - __main__ - INFO - Splits saved to run_20250919_072837/splits.json
2025-09-19 08:06:09,039 - __main__ - INFO - All training artifacts saved to run_20250919_072837
2025-09-19 08:06:09,039 - __main__ - INFO - Training completed successfully! Training time: 37m 9.2s | Results saved to: run_20250919_072837
{'eval_accuracy': 0.83078231292517, 'eval_loss': 0.2035590410232544, 'epoch': 9.857142857142858}
{'train_runtime': 2228.9981, 'train_samples_per_second': 21.857, 'train_steps_per_second': 0.301, 'train_loss': 0.056533169629636094, 'epoch': 9.857142857142858}
[INFO] Collecting artifacts to /homes/nnebeling/thesis/runs/ast-a40.162942 ...
  -> copying run_20250919_072837
  -> skipping ast_triplet_output (empty directory)
  -> skipping logs (empty directory)
[DONE] Everything copied to: /homes/nnebeling/thesis/runs/ast-a40.162942
Job runtime: 2265 seconds (00:37:45)
