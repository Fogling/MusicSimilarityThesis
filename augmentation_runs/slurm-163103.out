[INFO] SLURM_JOB_TMP is: /local/slurmjobs/163103
[INFO] Using GPU: 0
[INFO] Staging archive to node SSD...
'/homes/nnebeling/thesis/precomputed_7G_2Chunk.zip' -> '/local/slurmjobs/163103/precomputed_7G_2Chunk.zip'
[INFO] Unpacking on SSD...
[OK] Unpacked. Top-level contents:
.
precomputed_7G_2Chunk
precomputed_7G_2Chunk/Party House
precomputed_7G_2Chunk/Party Goa
precomputed_7G_2Chunk/Dark Techno
precomputed_7G_2Chunk/Zyzz Music
precomputed_7G_2Chunk/Chill House
precomputed_7G_2Chunk/Emotional Techno
precomputed_7G_2Chunk/Chiller vibe goa
[INFO] Starting training...
2025-09-21 17:39:25,985 - __main__ - INFO - Loading configuration...
2025-09-21 17:39:25,986 - __main__ - INFO - set_float32_matmul_precision=high
2025-09-21 17:39:25,986 - __main__ - INFO - TF32: matmul=True, cudnn=True
2025-09-21 17:39:26,454 - __main__ - INFO - Experiment: 4x4 with Strong Augmentations
2025-09-21 17:39:26,454 - __main__ - INFO - Description: Dataset size 4x4 (4 positive tracks, 4 triplets each) with strong augmentations to combat fast overfitting
2025-09-21 17:39:26,459 - __main__ - INFO - Random seeds set to 13
2025-09-21 17:39:26,459 - __main__ - INFO - Loading data splits...
2025-09-21 17:39:26,459 - __main__ - INFO - Generating train/test splits from preprocessed features
2025-09-21 17:39:26,459 - __main__ - INFO - Generating track-level splits to prevent data leakage...
2025-09-21 17:39:26,461 - __main__ - INFO - Subgenre Chill House: 81 tracks, 162 chunks total
2025-09-21 17:39:26,461 - __main__ - INFO - Subgenre Chiller vibe goa: 54 tracks, 108 chunks total
2025-09-21 17:39:26,463 - __main__ - INFO - Subgenre Dark Techno: 86 tracks, 172 chunks total
2025-09-21 17:39:26,464 - __main__ - INFO - Subgenre Emotional Techno: 75 tracks, 150 chunks total
2025-09-21 17:39:26,464 - __main__ - INFO - Subgenre Party Goa: 62 tracks, 124 chunks total
2025-09-21 17:39:26,465 - __main__ - INFO - Subgenre Party House: 69 tracks, 138 chunks total
2025-09-21 17:39:26,466 - __main__ - INFO - Subgenre Zyzz Music: 77 tracks, 154 chunks total
2025-09-21 17:39:26,466 - __main__ - INFO - Subgenre Chill House: 65 train tracks, 16 test tracks
2025-09-21 17:39:26,466 - __main__ - INFO - Subgenre Chiller vibe goa: 44 train tracks, 10 test tracks
2025-09-21 17:39:26,467 - __main__ - INFO - Subgenre Dark Techno: 69 train tracks, 17 test tracks
2025-09-21 17:39:26,467 - __main__ - INFO - Subgenre Emotional Techno: 60 train tracks, 15 test tracks
2025-09-21 17:39:26,467 - __main__ - INFO - Subgenre Party Goa: 50 train tracks, 12 test tracks
2025-09-21 17:39:26,467 - __main__ - INFO - Subgenre Party House: 56 train tracks, 13 test tracks
2025-09-21 17:39:26,467 - __main__ - INFO - Subgenre Zyzz Music: 62 train tracks, 15 test tracks
2025-09-21 17:39:26,467 - __main__ - INFO - Generating training triplets from train tracks...
2025-09-21 17:39:26,467 - __main__ - INFO - Train triplet generation config:
2025-09-21 17:39:26,467 - __main__ - INFO -   Max positive tracks per anchor: 4
2025-09-21 17:39:26,467 - __main__ - INFO -   Triplets per positive track: 4
2025-09-21 17:39:26,467 - __main__ - INFO -   Expected triplets per anchor: ~16
2025-09-21 17:39:26,469 - __main__ - INFO - Train - Subgenre Chill House: 1040 triplets from 65 tracks
2025-09-21 17:39:26,470 - __main__ - INFO - Train - Subgenre Chiller vibe goa: 704 triplets from 44 tracks
2025-09-21 17:39:26,472 - __main__ - INFO - Train - Subgenre Dark Techno: 1104 triplets from 69 tracks
2025-09-21 17:39:26,474 - __main__ - INFO - Train - Subgenre Emotional Techno: 960 triplets from 60 tracks
2025-09-21 17:39:26,476 - __main__ - INFO - Train - Subgenre Party Goa: 800 triplets from 50 tracks
2025-09-21 17:39:26,478 - __main__ - INFO - Train - Subgenre Party House: 896 triplets from 56 tracks
2025-09-21 17:39:26,480 - __main__ - INFO - Train - Subgenre Zyzz Music: 992 triplets from 62 tracks
2025-09-21 17:39:26,480 - __main__ - INFO - Generating test triplets from test tracks...
2025-09-21 17:39:26,480 - __main__ - INFO - Test triplet generation config:
2025-09-21 17:39:26,480 - __main__ - INFO -   Max positive tracks per anchor: 4
2025-09-21 17:39:26,480 - __main__ - INFO -   Triplets per positive track: 4
2025-09-21 17:39:26,480 - __main__ - INFO -   Expected triplets per anchor: ~16
2025-09-21 17:39:26,480 - __main__ - INFO - Test - Subgenre Chill House: 256 triplets from 16 tracks
2025-09-21 17:39:26,481 - __main__ - INFO - Test - Subgenre Chiller vibe goa: 160 triplets from 10 tracks
2025-09-21 17:39:26,481 - __main__ - INFO - Test - Subgenre Dark Techno: 272 triplets from 17 tracks
2025-09-21 17:39:26,482 - __main__ - INFO - Test - Subgenre Emotional Techno: 240 triplets from 15 tracks
2025-09-21 17:39:26,482 - __main__ - INFO - Test - Subgenre Party Goa: 192 triplets from 12 tracks
2025-09-21 17:39:26,482 - __main__ - INFO - Test - Subgenre Party House: 208 triplets from 13 tracks
2025-09-21 17:39:26,483 - __main__ - INFO - Test - Subgenre Zyzz Music: 240 triplets from 15 tracks
2025-09-21 17:39:26,483 - __main__ - INFO - ✓ NO DATA LEAKAGE: 406 unique train tracks, 98 unique test tracks
2025-09-21 17:39:26,483 - __main__ - INFO - Total: 6496 train triplets, 1568 test triplets
2025-09-21 17:39:26,483 - __main__ - INFO - Creating datasets...
2025-09-21 17:39:26,558 - __main__ - INFO - Initialized dataset (train) with 6496 triplets (resample_train_samples=False)
2025-09-21 17:39:26,576 - __main__ - INFO - Initialized dataset (test) with 1568 triplets (resample_train_samples=False)
2025-09-21 17:39:26,576 - __main__ - INFO - Augmentations enabled - wrapping datasets...
2025-09-21 17:39:26,579 - augmentations - INFO - SpectrogramAugmentations initialized: time_mask=0.3, freq_mask=0.3, noise=0.5, mixup=0.2
2025-09-21 17:39:26,579 - augmentations - INFO - AST2DSpectrogramAugmentations initialized: freq_mask=0.4, time_mask=0.4
2025-09-21 17:39:26,579 - augmentations - INFO - AugmentationPipeline initialized: enabled=True, 2d_aug=True, prob=0.7
2025-09-21 17:39:26,579 - dataset_augmented - INFO - AugmentedTripletFeatureDataset initialized for train split: augmentations_enabled=True, base_dataset_size=6496
2025-09-21 17:39:26,579 - __main__ - INFO - Train dataset: augmentations ENABLED
2025-09-21 17:39:26,579 - __main__ - INFO - Test dataset: augmentations DISABLED
2025-09-21 17:39:26,579 - __main__ - INFO - Initializing model...
2025-09-21 17:39:26,579 - __main__ - INFO - Using device: cuda
2025-09-21 17:39:26,579 - __main__ - INFO - Loading pretrained model: MIT/ast-finetuned-audioset-10-10-0.4593
2025-09-21 17:39:28,749 - __main__ - INFO - MLP Projection Head Architecture: 768 -> 512 -> 128
2025-09-21 17:39:28,750 - __main__ - INFO -   Activation: relu, Dropout: 0.15
2025-09-21 17:39:28,750 - __main__ - INFO -   Total parameters: 459,392
2025-09-21 17:39:28,750 - __main__ - INFO - Model initialized with projection to 128D
2025-09-21 17:39:28,750 - __main__ - INFO - Margin scheduling: 0.5 → 0.5 over 1 epochs
2025-09-21 17:39:28,750 - __main__ - INFO - Negative mining: none
2025-09-21 17:39:29,058 - __main__ - INFO - Using custom dual-group optimizer with sophisticated LR scheduling
2025-09-21 17:39:29,058 - lr_scheduler - INFO - Parameter groups created:
2025-09-21 17:39:29,058 - lr_scheduler - INFO -   Base parameters: 199 tensors
2025-09-21 17:39:29,059 - lr_scheduler - INFO -   Head parameters: 4 tensors
2025-09-21 17:39:29,059 - lr_scheduler - INFO - Dual group optimizer created:
2025-09-21 17:39:29,059 - lr_scheduler - INFO -   Base LR: 2.00e-05
2025-09-21 17:39:29,059 - lr_scheduler - INFO -   Head LR: 2.00e-05 (1.0x multiplier)
2025-09-21 17:39:29,059 - __main__ - INFO - Precision summary -> bf16=True, fp16=False, tf32=True
2025-09-21 17:39:29,092 - __main__ - INFO - Early stopping enabled: patience=4, min_delta=0.01, post_resample_grace=2
2025-09-21 17:39:29,092 - lr_scheduler - INFO - PyTorch LambdaLR scheduler created:
2025-09-21 17:39:29,092 - lr_scheduler - INFO -   Base LR: 2.00e-05
2025-09-21 17:39:29,092 - lr_scheduler - INFO -   Head LR multiplier: 1.0x
2025-09-21 17:39:29,092 - lr_scheduler - INFO -   Multiplier converges to 1.0 at epoch 1
2025-09-21 17:39:29,092 - lr_scheduler - INFO -   Warmup steps: 136 (10.0%)
2025-09-21 17:39:29,092 - lr_scheduler - INFO -   Total steps: 1365
2025-09-21 17:39:29,092 - lr_scheduler - INFO -   Min LR: 1.00e-07
2025-09-21 17:39:29,092 - lr_scheduler - INFO -   Scheduler type: Linear
2025-09-21 17:39:29,092 - __main__ - INFO - PyTorch LambdaLR scheduler created with 1365 total steps, 91 steps/epoch
2025-09-21 17:39:29,099 - __main__ - INFO - Training setup:
2025-09-21 17:39:29,100 - __main__ - INFO -   - Train samples: 6496
2025-09-21 17:39:29,100 - __main__ - INFO -   - Test samples: 1568
2025-09-21 17:39:29,100 - __main__ - INFO -   - Batch size: 24
2025-09-21 17:39:29,100 - __main__ - INFO -   - Gradient accumulation: 3
2025-09-21 17:39:29,100 - __main__ - INFO -   - Effective batch size: 72
2025-09-21 17:39:29,100 - __main__ - INFO -   - Steps per epoch: 91
2025-09-21 17:39:29,100 - __main__ - INFO -   - Total epochs: 15
2025-09-21 17:39:29,100 - __main__ - INFO -   - Estimated total steps: 1365
2025-09-21 17:39:29,100 - __main__ - INFO - Performing initial evaluation to establish baseline...
2025-09-21 17:39:54,519 - __main__ - INFO - Evaluation - Epoch 0, Step 0: eval_loss=0.4894, eval_accuracy=0.610, Elapsed: 0.0s
2025-09-21 17:39:54,520 - __main__ - INFO - Starting training...
2025-09-21 17:39:54,818 - __main__ - INFO - Using stratified batch sampling for training
2025-09-21 17:39:54,820 - __main__ - INFO - Stratified batching: 7 subgenres, 2 guaranteed per subgenre, 10 random slots per batch
2025-09-21 17:39:54,828 - __main__ - INFO - Training started at 2025-09-21 17:39:54
2025-09-21 17:39:54,828 - __main__ - INFO - Epoch 0: Using margin 0.500
{'eval_accuracy': 0.6096938775510204, 'eval_loss': 0.4894464910030365}
{'loss': 0.3907, 'grad_norm': 1.3175129890441895, 'learning_rate': 1.3382352941176471e-05, 'epoch': 1.0}
2025-09-21 17:45:04,270 - __main__ - INFO - Evaluation - Epoch 1.0, Step 91: eval_loss=0.2595, eval_accuracy=0.782, Elapsed: 5m 9.4s
2025-09-21 17:45:04,270 - __main__ - INFO - Epoch 1: Using margin 0.500
{'eval_accuracy': 0.7818877551020408, 'eval_loss': 0.2595313489437103, 'epoch': 1.0}
{'loss': 0.1554, 'grad_norm': 0.8037777543067932, 'learning_rate': 1.9251423921887715e-05, 'epoch': 2.0}
2025-09-21 17:50:10,141 - __main__ - INFO - Evaluation - Epoch 2.0, Step 182: eval_loss=0.1943, eval_accuracy=0.837, Elapsed: 10m 15.3s
2025-09-21 17:50:10,141 - __main__ - INFO - Epoch 2: Using margin 0.500
{'eval_accuracy': 0.8373724489795918, 'eval_loss': 0.1942601054906845, 'epoch': 2.0}
{'loss': 0.0613, 'grad_norm': 0.8322198390960693, 'learning_rate': 1.7770545158665583e-05, 'epoch': 3.0}
2025-09-21 17:55:13,782 - __main__ - INFO - Evaluation - Epoch 3.0, Step 273: eval_loss=0.1945, eval_accuracy=0.843, Elapsed: 15m 19.0s
2025-09-21 17:55:13,783 - __main__ - INFO - Epoch 3: Using margin 0.500
{'eval_accuracy': 0.8431122448979592, 'eval_loss': 0.19453684985637665, 'epoch': 3.0}
{'loss': 0.0441, 'grad_norm': 0.907791018486023, 'learning_rate': 1.628966639544345e-05, 'epoch': 4.0}
2025-09-21 18:00:17,029 - __main__ - INFO - Evaluation - Epoch 4.0, Step 364: eval_loss=0.2116, eval_accuracy=0.809, Elapsed: 20m 22.2s
2025-09-21 18:00:17,966 - __main__ - INFO - Epoch 4: Using margin 0.500
{'eval_accuracy': 0.8093112244897959, 'eval_loss': 0.21163170039653778, 'epoch': 4.0}
{'loss': 0.0282, 'grad_norm': 0.8602115511894226, 'learning_rate': 1.480878763222132e-05, 'epoch': 5.0}
2025-09-21 18:05:21,192 - __main__ - INFO - Evaluation - Epoch 5.0, Step 455: eval_loss=0.1985, eval_accuracy=0.833, Elapsed: 25m 26.4s
2025-09-21 18:05:21,193 - __main__ - INFO - Epoch 5: Using margin 0.500
{'eval_accuracy': 0.8329081632653061, 'eval_loss': 0.19852665066719055, 'epoch': 5.0}
{'loss': 0.0153, 'grad_norm': 0.4882103502750397, 'learning_rate': 1.3327908868999187e-05, 'epoch': 6.0}
2025-09-21 18:10:23,868 - __main__ - INFO - Evaluation - Epoch 6.0, Step 546: eval_loss=0.2056, eval_accuracy=0.829, Elapsed: 30m 29.0s
2025-09-21 18:10:23,868 - __main__ - INFO - Epoch 6: Using margin 0.500
{'eval_accuracy': 0.8290816326530612, 'eval_loss': 0.20560933649539948, 'epoch': 6.0}
{'loss': 0.0111, 'grad_norm': 0.3819887340068817, 'learning_rate': 1.1847030105777055e-05, 'epoch': 7.0}
2025-09-21 18:15:26,532 - __main__ - INFO - Evaluation - Epoch 7.0, Step 637: eval_loss=0.1910, eval_accuracy=0.847, Elapsed: 35m 31.7s
2025-09-21 18:15:26,533 - __main__ - INFO - Epoch 7: Using margin 0.500
{'eval_accuracy': 0.8469387755102041, 'eval_loss': 0.191015362739563, 'epoch': 7.0}
{'loss': 0.0075, 'grad_norm': 0.0, 'learning_rate': 1.0366151342554925e-05, 'epoch': 8.0}
2025-09-21 18:20:28,759 - __main__ - INFO - Evaluation - Epoch 8.0, Step 728: eval_loss=0.1978, eval_accuracy=0.839, Elapsed: 40m 33.9s
2025-09-21 18:20:28,760 - __main__ - INFO - Epoch 8: Using margin 0.500
{'eval_accuracy': 0.8392857142857143, 'eval_loss': 0.1977522373199463, 'epoch': 8.0}
{'loss': 0.0041, 'grad_norm': 0.27535542845726013, 'learning_rate': 8.885272579332792e-06, 'epoch': 9.0}
2025-09-21 18:25:31,313 - __main__ - INFO - Evaluation - Epoch 9.0, Step 819: eval_loss=0.1960, eval_accuracy=0.842, Elapsed: 45m 36.5s
2025-09-21 18:25:31,313 - __main__ - INFO - Epoch 9: Using margin 0.500
{'eval_accuracy': 0.8418367346938775, 'eval_loss': 0.1959960162639618, 'epoch': 9.0}
{'loss': 0.0033, 'grad_norm': 0.392728716135025, 'learning_rate': 7.40439381611066e-06, 'epoch': 10.0}
2025-09-21 18:30:33,623 - __main__ - INFO - Evaluation - Epoch 10.0, Step 910: eval_loss=0.2044, eval_accuracy=0.829, Elapsed: 50m 38.8s
2025-09-21 18:30:33,624 - __main__ - INFO - Epoch 10: Using margin 0.500
{'eval_accuracy': 0.8290816326530612, 'eval_loss': 0.2044471651315689, 'epoch': 10.0}
{'loss': 0.0021, 'grad_norm': 0.0, 'learning_rate': 5.923515052888529e-06, 'epoch': 11.0}
2025-09-21 18:35:35,616 - __main__ - INFO - Evaluation - Epoch 11.0, Step 1001: eval_loss=0.1994, eval_accuracy=0.835, Elapsed: 55m 40.8s
2025-09-21 18:35:35,616 - __main__ - INFO - Epoch 11: Using margin 0.500
{'eval_accuracy': 0.8354591836734694, 'eval_loss': 0.199422687292099, 'epoch': 11.0}
{'loss': 0.0017, 'grad_norm': 0.0, 'learning_rate': 4.442636289666396e-06, 'epoch': 12.0}
2025-09-21 18:40:37,740 - __main__ - INFO - Evaluation - Epoch 12.0, Step 1092: eval_loss=0.1910, eval_accuracy=0.840, Elapsed: 1h 0m 42.9s
2025-09-21 18:40:37,740 - __main__ - INFO - Epoch 12: Using margin 0.500
{'eval_accuracy': 0.8399234693877551, 'eval_loss': 0.19097226858139038, 'epoch': 12.0}
{'loss': 0.0014, 'grad_norm': 0.0, 'learning_rate': 2.9617575264442646e-06, 'epoch': 13.0}
2025-09-21 18:45:39,602 - __main__ - INFO - Evaluation - Epoch 13.0, Step 1183: eval_loss=0.1934, eval_accuracy=0.848, Elapsed: 1h 5m 44.8s
2025-09-21 18:45:39,602 - __main__ - INFO - Epoch 13: Using margin 0.500
{'eval_accuracy': 0.8475765306122449, 'eval_loss': 0.19335855543613434, 'epoch': 13.0}
{'loss': 0.0007, 'grad_norm': 0.0, 'learning_rate': 1.480878763222131e-06, 'epoch': 14.0}
2025-09-21 18:50:41,875 - __main__ - INFO - Evaluation - Epoch 14.0, Step 1274: eval_loss=0.1954, eval_accuracy=0.836, Elapsed: 1h 10m 47.0s
2025-09-21 18:50:41,875 - __main__ - INFO - Epoch 14: Using margin 0.500
{'eval_accuracy': 0.8360969387755102, 'eval_loss': 0.19542384147644043, 'epoch': 14.0}
{'loss': 0.0007, 'grad_norm': 0.0, 'learning_rate': 2.4410089503661415e-07, 'epoch': 14.841328413284133}
2025-09-21 18:54:59,951 - __main__ - INFO - Evaluation - Epoch 14.841328413284133, Step 1350: eval_loss=0.1964, eval_accuracy=0.834, Elapsed: 1h 15m 5.1s
2025-09-21 18:54:59,954 - __main__ - INFO - Training completed! Total training time: 1h 15m 5.1s
2025-09-21 18:54:59,954 - __main__ - INFO - Training ended at 2025-09-21 18:54:59
2025-09-21 18:54:59,954 - __main__ - INFO - [EarlyStopping] Training completed normally with final best accuracy: -inf
2025-09-21 18:54:59,954 - __main__ - INFO - Saving model and artifacts...
2025-09-21 18:55:01,229 - __main__ - INFO - Model saved to run_20250921_173926/model.safetensors
2025-09-21 18:55:01,231 - __main__ - INFO - Configuration saved to run_20250921_173926/config.json
2025-09-21 18:55:01,264 - __main__ - INFO - Splits saved to run_20250921_173926/splits.json
2025-09-21 18:55:01,264 - __main__ - INFO - All training artifacts saved to run_20250921_173926
2025-09-21 18:55:01,264 - __main__ - INFO - Training completed successfully! Training time: 1h 15m 5.4s | Results saved to: run_20250921_173926
{'eval_accuracy': 0.8335459183673469, 'eval_loss': 0.19637207686901093, 'epoch': 14.841328413284133}
{'train_runtime': 4505.1253, 'train_samples_per_second': 21.629, 'train_steps_per_second': 0.3, 'train_loss': 0.049042303380039, 'epoch': 14.841328413284133}
[INFO] Collecting artifacts to /homes/nnebeling/thesis/runs/ast-a40.163103 ...
  -> copying run_20250921_173926
[DONE] Everything copied to: /homes/nnebeling/thesis/runs/ast-a40.163103
Job runtime: 4552 seconds (01:15:52)
