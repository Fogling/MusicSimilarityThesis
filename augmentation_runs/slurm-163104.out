[INFO] SLURM_JOB_TMP is: /local/slurmjobs/163104
[INFO] Using GPU: 0
[INFO] Staging archive to node SSD...
'/homes/nnebeling/thesis/precomputed_7G_2Chunk.zip' -> '/local/slurmjobs/163104/precomputed_7G_2Chunk.zip'
[INFO] Unpacking on SSD...
[OK] Unpacked. Top-level contents:
.
precomputed_7G_2Chunk
precomputed_7G_2Chunk/Party House
precomputed_7G_2Chunk/Party Goa
precomputed_7G_2Chunk/Dark Techno
precomputed_7G_2Chunk/Zyzz Music
precomputed_7G_2Chunk/Chill House
precomputed_7G_2Chunk/Emotional Techno
precomputed_7G_2Chunk/Chiller vibe goa
[INFO] Starting training...
2025-09-21 17:40:12,511 - __main__ - INFO - Loading configuration...
2025-09-21 17:40:12,512 - __main__ - INFO - set_float32_matmul_precision=high
2025-09-21 17:40:12,512 - __main__ - INFO - TF32: matmul=True, cudnn=True
2025-09-21 17:40:12,875 - __main__ - INFO - Experiment: 6x2 with Aggressive Augmentations
2025-09-21 17:40:12,875 - __main__ - INFO - Description: Large dataset (6x2 = ~12 triplets per anchor) with aggressive augmentations to combat rapid overfitting
2025-09-21 17:40:12,877 - __main__ - INFO - Random seeds set to 13
2025-09-21 17:40:12,877 - __main__ - INFO - Loading data splits...
2025-09-21 17:40:12,877 - __main__ - INFO - Generating train/test splits from preprocessed features
2025-09-21 17:40:12,877 - __main__ - INFO - Generating track-level splits to prevent data leakage...
2025-09-21 17:40:12,878 - __main__ - INFO - Subgenre Chill House: 81 tracks, 162 chunks total
2025-09-21 17:40:12,879 - __main__ - INFO - Subgenre Chiller vibe goa: 54 tracks, 108 chunks total
2025-09-21 17:40:12,880 - __main__ - INFO - Subgenre Dark Techno: 86 tracks, 172 chunks total
2025-09-21 17:40:12,881 - __main__ - INFO - Subgenre Emotional Techno: 75 tracks, 150 chunks total
2025-09-21 17:40:12,882 - __main__ - INFO - Subgenre Party Goa: 62 tracks, 124 chunks total
2025-09-21 17:40:12,883 - __main__ - INFO - Subgenre Party House: 69 tracks, 138 chunks total
2025-09-21 17:40:12,884 - __main__ - INFO - Subgenre Zyzz Music: 77 tracks, 154 chunks total
2025-09-21 17:40:12,884 - __main__ - INFO - Subgenre Chill House: 65 train tracks, 16 test tracks
2025-09-21 17:40:12,884 - __main__ - INFO - Subgenre Chiller vibe goa: 44 train tracks, 10 test tracks
2025-09-21 17:40:12,884 - __main__ - INFO - Subgenre Dark Techno: 69 train tracks, 17 test tracks
2025-09-21 17:40:12,884 - __main__ - INFO - Subgenre Emotional Techno: 60 train tracks, 15 test tracks
2025-09-21 17:40:12,884 - __main__ - INFO - Subgenre Party Goa: 50 train tracks, 12 test tracks
2025-09-21 17:40:12,884 - __main__ - INFO - Subgenre Party House: 56 train tracks, 13 test tracks
2025-09-21 17:40:12,884 - __main__ - INFO - Subgenre Zyzz Music: 62 train tracks, 15 test tracks
2025-09-21 17:40:12,884 - __main__ - INFO - Generating training triplets from train tracks...
2025-09-21 17:40:12,884 - __main__ - INFO - Train triplet generation config:
2025-09-21 17:40:12,884 - __main__ - INFO -   Max positive tracks per anchor: 6
2025-09-21 17:40:12,884 - __main__ - INFO -   Triplets per positive track: 2
2025-09-21 17:40:12,884 - __main__ - INFO -   Expected triplets per anchor: ~12
2025-09-21 17:40:12,887 - __main__ - INFO - Train - Subgenre Chill House: 1560 triplets from 65 tracks
2025-09-21 17:40:12,889 - __main__ - INFO - Train - Subgenre Chiller vibe goa: 1056 triplets from 44 tracks
2025-09-21 17:40:12,892 - __main__ - INFO - Train - Subgenre Dark Techno: 1656 triplets from 69 tracks
2025-09-21 17:40:12,896 - __main__ - INFO - Train - Subgenre Emotional Techno: 1440 triplets from 60 tracks
2025-09-21 17:40:12,898 - __main__ - INFO - Train - Subgenre Party Goa: 1200 triplets from 50 tracks
2025-09-21 17:40:12,900 - __main__ - INFO - Train - Subgenre Party House: 1344 triplets from 56 tracks
2025-09-21 17:40:12,903 - __main__ - INFO - Train - Subgenre Zyzz Music: 1488 triplets from 62 tracks
2025-09-21 17:40:12,903 - __main__ - INFO - Generating test triplets from test tracks...
2025-09-21 17:40:12,903 - __main__ - INFO - Test triplet generation config:
2025-09-21 17:40:12,903 - __main__ - INFO -   Max positive tracks per anchor: 6
2025-09-21 17:40:12,903 - __main__ - INFO -   Triplets per positive track: 2
2025-09-21 17:40:12,903 - __main__ - INFO -   Expected triplets per anchor: ~12
2025-09-21 17:40:12,904 - __main__ - INFO - Test - Subgenre Chill House: 384 triplets from 16 tracks
2025-09-21 17:40:12,904 - __main__ - INFO - Test - Subgenre Chiller vibe goa: 240 triplets from 10 tracks
2025-09-21 17:40:12,905 - __main__ - INFO - Test - Subgenre Dark Techno: 408 triplets from 17 tracks
2025-09-21 17:40:12,906 - __main__ - INFO - Test - Subgenre Emotional Techno: 360 triplets from 15 tracks
2025-09-21 17:40:12,906 - __main__ - INFO - Test - Subgenre Party Goa: 288 triplets from 12 tracks
2025-09-21 17:40:12,907 - __main__ - INFO - Test - Subgenre Party House: 312 triplets from 13 tracks
2025-09-21 17:40:12,908 - __main__ - INFO - Test - Subgenre Zyzz Music: 360 triplets from 15 tracks
2025-09-21 17:40:12,908 - __main__ - INFO - ✓ NO DATA LEAKAGE: 406 unique train tracks, 98 unique test tracks
2025-09-21 17:40:12,908 - __main__ - INFO - Total: 9744 train triplets, 2352 test triplets
2025-09-21 17:40:12,908 - __main__ - INFO - Creating datasets...
2025-09-21 17:40:13,026 - __main__ - INFO - Initialized dataset (train) with 9744 triplets (resample_train_samples=False)
2025-09-21 17:40:13,052 - __main__ - INFO - Initialized dataset (test) with 2352 triplets (resample_train_samples=False)
2025-09-21 17:40:13,052 - __main__ - INFO - Augmentations enabled - wrapping datasets...
2025-09-21 17:40:13,053 - augmentations - INFO - SpectrogramAugmentations initialized: time_mask=0.3, freq_mask=0.3, noise=0.5, mixup=0.2
2025-09-21 17:40:13,053 - augmentations - INFO - AST2DSpectrogramAugmentations initialized: freq_mask=0.4, time_mask=0.4
2025-09-21 17:40:13,053 - augmentations - INFO - AugmentationPipeline initialized: enabled=True, 2d_aug=True, prob=0.7
2025-09-21 17:40:13,053 - dataset_augmented - INFO - AugmentedTripletFeatureDataset initialized for train split: augmentations_enabled=True, base_dataset_size=9744
2025-09-21 17:40:13,053 - __main__ - INFO - Train dataset: augmentations ENABLED
2025-09-21 17:40:13,053 - __main__ - INFO - Test dataset: augmentations DISABLED
2025-09-21 17:40:13,053 - __main__ - INFO - Initializing model...
2025-09-21 17:40:13,053 - __main__ - INFO - Using device: cuda
2025-09-21 17:40:13,053 - __main__ - INFO - Loading pretrained model: MIT/ast-finetuned-audioset-10-10-0.4593
2025-09-21 17:40:14,808 - __main__ - INFO - MLP Projection Head Architecture: 768 -> 512 -> 128
2025-09-21 17:40:14,808 - __main__ - INFO -   Activation: relu, Dropout: 0.15
2025-09-21 17:40:14,808 - __main__ - INFO -   Total parameters: 459,392
2025-09-21 17:40:14,808 - __main__ - INFO - Model initialized with projection to 128D
2025-09-21 17:40:14,808 - __main__ - INFO - Margin scheduling: 0.5 → 0.5 over 1 epochs
2025-09-21 17:40:14,808 - __main__ - INFO - Negative mining: none
2025-09-21 17:40:15,033 - __main__ - INFO - Using custom dual-group optimizer with sophisticated LR scheduling
2025-09-21 17:40:15,033 - lr_scheduler - INFO - Parameter groups created:
2025-09-21 17:40:15,033 - lr_scheduler - INFO -   Base parameters: 199 tensors
2025-09-21 17:40:15,033 - lr_scheduler - INFO -   Head parameters: 4 tensors
2025-09-21 17:40:15,034 - lr_scheduler - INFO - Dual group optimizer created:
2025-09-21 17:40:15,034 - lr_scheduler - INFO -   Base LR: 2.00e-05
2025-09-21 17:40:15,034 - lr_scheduler - INFO -   Head LR: 2.00e-05 (1.0x multiplier)
2025-09-21 17:40:15,034 - __main__ - INFO - Precision summary -> bf16=True, fp16=False, tf32=True
2025-09-21 17:40:15,061 - __main__ - INFO - Early stopping enabled: patience=4, min_delta=0.01, post_resample_grace=2
2025-09-21 17:40:15,061 - lr_scheduler - INFO - PyTorch LambdaLR scheduler created:
2025-09-21 17:40:15,061 - lr_scheduler - INFO -   Base LR: 2.00e-05
2025-09-21 17:40:15,061 - lr_scheduler - INFO -   Head LR multiplier: 1.0x
2025-09-21 17:40:15,061 - lr_scheduler - INFO -   Multiplier converges to 1.0 at epoch 1
2025-09-21 17:40:15,061 - lr_scheduler - INFO -   Warmup steps: 204 (10.0%)
2025-09-21 17:40:15,061 - lr_scheduler - INFO -   Total steps: 2040
2025-09-21 17:40:15,061 - lr_scheduler - INFO -   Min LR: 1.00e-07
2025-09-21 17:40:15,061 - lr_scheduler - INFO -   Scheduler type: Linear
2025-09-21 17:40:15,061 - __main__ - INFO - PyTorch LambdaLR scheduler created with 2040 total steps, 136 steps/epoch
2025-09-21 17:40:15,068 - __main__ - INFO - Training setup:
2025-09-21 17:40:15,068 - __main__ - INFO -   - Train samples: 9744
2025-09-21 17:40:15,068 - __main__ - INFO -   - Test samples: 2352
2025-09-21 17:40:15,068 - __main__ - INFO -   - Batch size: 24
2025-09-21 17:40:15,068 - __main__ - INFO -   - Gradient accumulation: 3
2025-09-21 17:40:15,068 - __main__ - INFO -   - Effective batch size: 72
2025-09-21 17:40:15,068 - __main__ - INFO -   - Steps per epoch: 136
2025-09-21 17:40:15,068 - __main__ - INFO -   - Total epochs: 15
2025-09-21 17:40:15,068 - __main__ - INFO -   - Estimated total steps: 2040
2025-09-21 17:40:15,068 - __main__ - INFO - Performing initial evaluation to establish baseline...
2025-09-21 17:40:51,436 - __main__ - INFO - Evaluation - Epoch 0, Step 0: eval_loss=0.4875, eval_accuracy=0.627, Elapsed: 0.0s
2025-09-21 17:40:51,437 - __main__ - INFO - Starting training...
2025-09-21 17:40:51,778 - __main__ - INFO - Using stratified batch sampling for training
2025-09-21 17:40:51,781 - __main__ - INFO - Stratified batching: 7 subgenres, 2 guaranteed per subgenre, 10 random slots per batch
2025-09-21 17:40:51,788 - __main__ - INFO - Training started at 2025-09-21 17:40:51
2025-09-21 17:40:51,789 - __main__ - INFO - Epoch 0: Using margin 0.500
{'eval_accuracy': 0.627125850340136, 'eval_loss': 0.4875237047672272}
{'loss': 0.3451, 'grad_norm': 1.35309636592865, 'learning_rate': 1.3333333333333333e-05, 'epoch': 1.0}
2025-09-21 17:48:33,754 - __main__ - INFO - Evaluation - Epoch 1.0, Step 136: eval_loss=0.2410, eval_accuracy=0.804, Elapsed: 7m 42.0s
2025-09-21 17:48:33,755 - __main__ - INFO - Epoch 1: Using margin 0.500
{'eval_accuracy': 0.8044217687074829, 'eval_loss': 0.24096021056175232, 'epoch': 1.0}
{'loss': 0.1071, 'grad_norm': 0.2645947337150574, 'learning_rate': 1.9259259259259263e-05, 'epoch': 2.0}
2025-09-21 17:56:08,966 - __main__ - INFO - Evaluation - Epoch 2.0, Step 272: eval_loss=0.1788, eval_accuracy=0.854, Elapsed: 15m 17.2s
2025-09-21 17:56:08,967 - __main__ - INFO - Epoch 2: Using margin 0.500
{'eval_accuracy': 0.8541666666666666, 'eval_loss': 0.17879395186901093, 'epoch': 2.0}
{'loss': 0.0507, 'grad_norm': 0.4645223319530487, 'learning_rate': 1.7777777777777777e-05, 'epoch': 3.0}
2025-09-21 18:03:41,947 - __main__ - INFO - Evaluation - Epoch 3.0, Step 408: eval_loss=0.1687, eval_accuracy=0.866, Elapsed: 22m 50.2s
2025-09-21 18:03:41,948 - __main__ - INFO - Epoch 3: Using margin 0.500
{'eval_accuracy': 0.8656462585034014, 'eval_loss': 0.1686919778585434, 'epoch': 3.0}
{'loss': 0.0299, 'grad_norm': 0.19628703594207764, 'learning_rate': 1.62962962962963e-05, 'epoch': 4.0}
2025-09-21 18:11:15,301 - __main__ - INFO - Evaluation - Epoch 4.0, Step 544: eval_loss=0.1787, eval_accuracy=0.853, Elapsed: 30m 23.5s
2025-09-21 18:11:15,302 - __main__ - INFO - Epoch 4: Using margin 0.500
{'eval_accuracy': 0.8533163265306123, 'eval_loss': 0.17868328094482422, 'epoch': 4.0}
{'loss': 0.0156, 'grad_norm': 0.0, 'learning_rate': 1.4814814814814815e-05, 'epoch': 5.0}
2025-09-21 18:18:47,858 - __main__ - INFO - Evaluation - Epoch 5.0, Step 680: eval_loss=0.1832, eval_accuracy=0.852, Elapsed: 37m 56.1s
2025-09-21 18:18:47,858 - __main__ - INFO - Epoch 5: Using margin 0.500
{'eval_accuracy': 0.8516156462585034, 'eval_loss': 0.18323077261447906, 'epoch': 5.0}
{'loss': 0.0075, 'grad_norm': 0.0, 'learning_rate': 1.3333333333333337e-05, 'epoch': 6.0}
2025-09-21 18:26:20,076 - __main__ - INFO - Evaluation - Epoch 6.0, Step 816: eval_loss=0.1791, eval_accuracy=0.851, Elapsed: 45m 28.3s
2025-09-21 18:26:20,077 - __main__ - INFO - Epoch 6: Using margin 0.500
{'eval_accuracy': 0.8507653061224489, 'eval_loss': 0.17905835807323456, 'epoch': 6.0}
{'loss': 0.0033, 'grad_norm': 0.48029759526252747, 'learning_rate': 1.1851851851851852e-05, 'epoch': 7.0}
2025-09-21 18:33:51,939 - __main__ - INFO - Evaluation - Epoch 7.0, Step 952: eval_loss=0.1914, eval_accuracy=0.838, Elapsed: 53m 0.2s
2025-09-21 18:33:51,940 - __main__ - INFO - Epoch 7: Using margin 0.500
{'eval_accuracy': 0.8384353741496599, 'eval_loss': 0.19138465821743011, 'epoch': 7.0}
{'loss': 0.0021, 'grad_norm': 0.0, 'learning_rate': 1.0370370370370373e-05, 'epoch': 8.0}
2025-09-21 18:41:24,715 - __main__ - INFO - Evaluation - Epoch 8.0, Step 1088: eval_loss=0.1919, eval_accuracy=0.845, Elapsed: 1h 0m 32.9s
2025-09-21 18:41:24,716 - __main__ - INFO - Epoch 8: Using margin 0.500
{'eval_accuracy': 0.8452380952380952, 'eval_loss': 0.1918702870607376, 'epoch': 8.0}
{'loss': 0.0029, 'grad_norm': 0.0, 'learning_rate': 8.888888888888888e-06, 'epoch': 9.0}
2025-09-21 18:48:56,936 - __main__ - INFO - Evaluation - Epoch 9.0, Step 1224: eval_loss=0.1801, eval_accuracy=0.851, Elapsed: 1h 8m 5.1s
2025-09-21 18:48:56,937 - __main__ - INFO - Epoch 9: Using margin 0.500
{'eval_accuracy': 0.8511904761904762, 'eval_loss': 0.18009167909622192, 'epoch': 9.0}
{'loss': 0.0011, 'grad_norm': 0.0, 'learning_rate': 7.4074074074074075e-06, 'epoch': 10.0}
2025-09-21 18:56:29,020 - __main__ - INFO - Evaluation - Epoch 10.0, Step 1360: eval_loss=0.1768, eval_accuracy=0.858, Elapsed: 1h 15m 37.2s
2025-09-21 18:56:29,021 - __main__ - INFO - Epoch 10: Using margin 0.500
{'eval_accuracy': 0.8575680272108843, 'eval_loss': 0.17676959931850433, 'epoch': 10.0}
{'loss': 0.001, 'grad_norm': 0.0, 'learning_rate': 5.925925925925926e-06, 'epoch': 11.0}
2025-09-21 19:04:01,332 - __main__ - INFO - Evaluation - Epoch 11.0, Step 1496: eval_loss=0.1769, eval_accuracy=0.861, Elapsed: 1h 23m 9.5s
2025-09-21 19:04:01,333 - __main__ - INFO - Epoch 11: Using margin 0.500
{'eval_accuracy': 0.860969387755102, 'eval_loss': 0.1768777072429657, 'epoch': 11.0}
{'loss': 0.0008, 'grad_norm': 0.0, 'learning_rate': 4.444444444444444e-06, 'epoch': 12.0}
2025-09-21 19:11:33,395 - __main__ - INFO - Evaluation - Epoch 12.0, Step 1632: eval_loss=0.1809, eval_accuracy=0.856, Elapsed: 1h 30m 41.6s
2025-09-21 19:11:33,397 - __main__ - INFO - Epoch 12: Using margin 0.500
{'eval_accuracy': 0.8558673469387755, 'eval_loss': 0.1808902770280838, 'epoch': 12.0}
{'loss': 0.0004, 'grad_norm': 0.0, 'learning_rate': 2.962962962962963e-06, 'epoch': 13.0}
2025-09-21 19:19:05,766 - __main__ - INFO - Evaluation - Epoch 13.0, Step 1768: eval_loss=0.1764, eval_accuracy=0.863, Elapsed: 1h 38m 14.0s
2025-09-21 19:19:05,767 - __main__ - INFO - Epoch 13: Using margin 0.500
{'eval_accuracy': 0.8630952380952381, 'eval_loss': 0.17637965083122253, 'epoch': 13.0}
{'loss': 0.0006, 'grad_norm': 0.0, 'learning_rate': 1.4814814814814815e-06, 'epoch': 14.0}
2025-09-21 19:26:37,778 - __main__ - INFO - Evaluation - Epoch 14.0, Step 1904: eval_loss=0.1721, eval_accuracy=0.867, Elapsed: 1h 45m 46.0s
2025-09-21 19:26:37,779 - __main__ - INFO - Epoch 14: Using margin 0.500
{'eval_accuracy': 0.8669217687074829, 'eval_loss': 0.17206649482250214, 'epoch': 14.0}
{'loss': 0.0006, 'grad_norm': 0.0, 'learning_rate': 1.6339869281045694e-07, 'epoch': 14.894088669950738}
2025-09-21 19:33:26,121 - __main__ - INFO - Evaluation - Epoch 14.894088669950738, Step 2025: eval_loss=0.1723, eval_accuracy=0.865, Elapsed: 1h 52m 34.3s
2025-09-21 19:33:26,123 - __main__ - INFO - Training completed! Total training time: 1h 52m 34.3s
2025-09-21 19:33:26,124 - __main__ - INFO - Training ended at 2025-09-21 19:33:26
2025-09-21 19:33:26,124 - __main__ - INFO - [EarlyStopping] Training completed normally with final best accuracy: -inf
2025-09-21 19:33:26,124 - __main__ - INFO - Saving model and artifacts...
2025-09-21 19:33:27,390 - __main__ - INFO - Model saved to run_20250921_174012/model.safetensors
2025-09-21 19:33:27,392 - __main__ - INFO - Configuration saved to run_20250921_174012/config.json
2025-09-21 19:33:27,438 - __main__ - INFO - Splits saved to run_20250921_174012/splits.json
2025-09-21 19:33:27,438 - __main__ - INFO - All training artifacts saved to run_20250921_174012
2025-09-21 19:33:27,439 - __main__ - INFO - Training completed successfully! Training time: 1h 52m 34.7s | Results saved to: run_20250921_174012
{'eval_accuracy': 0.8647959183673469, 'eval_loss': 0.172298863530159, 'epoch': 14.894088669950738}
{'train_runtime': 6754.3342, 'train_samples_per_second': 21.639, 'train_steps_per_second': 0.3, 'train_loss': 0.03818773798736525, 'epoch': 14.894088669950738}
[INFO] Collecting artifacts to /homes/nnebeling/thesis/runs/ast-a40.163104 ...
  -> copying run_20250921_174012
[DONE] Everything copied to: /homes/nnebeling/thesis/runs/ast-a40.163104
Job runtime: 6809 seconds (01:53:29)
